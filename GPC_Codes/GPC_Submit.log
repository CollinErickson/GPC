
R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> # This file is submitted by GPC_Submit.pbs
> # Only the function calls you want to run should be uncommented.
> # This file contains all of the function calls I've used. 
> #   It's an easy way to go back and rerun things or saw what I ran before.
> 
> timestamp()
##------ Wed Jan 11 09:56:03 2017 ------##
> setwd('~/Research/GPC/GPC_Codes')
> source('./GPC_Main.R')
Loading required package: GPfit
Loading required package: mlegp
Loading required package: DiceKriging
Loading required package: lhs
Loading required package: png
Loading required package: grid
Loading required package: knitr
Loading required package: plyr
Loading required package: MASS
Loading required package: laGP
> 
> # qsub <- function() {system('qsub /sscc/home/c/cbe117/Research/GPC/GPC_Codes/GPC_Submit.pbs')}
> # pbstat <- function() {system('pbstat')}
> # system('qsub /sscc/home/c/cbe117/Research/GPC/GPC_Codes/GPC_Submit.pbs -a 0254') # submit at a certain time
> 
> 
> # Redoing everything, including JMP separately
> #Borehole1357_03(stepstorun=3,laGP.nuggets=c('E',1e-6),laGP.nuggets.names=c('E',6),JMP.include=T,external.fits='JMP')
> #Borehole03(stepstorun=3,laGP.nuggets=c('E',1e-6),laGP.nuggets.names=c('E',6),JMP.include=T,external.fits='JMP')
> #OTLCircuit2(stepstorun=3, laGP.nuggets=c('E',1e-6),laGP.nuggets.names=c('E',6),JMP.include=T,external.fits='JMP')
> #Detpep108d2(stepstorun=3, laGP.nuggets=c('E',1e-6),laGP.nuggets.names=c('E',6),JMP.include=T,external.fits='JMP', GPfit.include=T)
> #RGPP2_D2_B.7( stepstorun=3, GPfit.powers=c(2), laGP.nuggets=c('E',1e-6),laGP.nuggets.names=c('E',6),JMP.include=T,external.fits='JMP')
> #RGPP2_D4_B.7( stepstorun=3, GPfit.powers=c(2), laGP.nuggets=c('E',1e-6),laGP.nuggets.names=c('E',6),JMP.include=T,external.fits='JMP')
> #RGPP2_D6_B.7( stepstorun=3, GPfit.powers=c(2), laGP.nuggets=c('E',1e-6),laGP.nuggets.names=c('E',6),JMP.include=T,external.fits='JMP')
> #RGPP2_D2_B1.3(stepstorun=3, GPfit.powers=c(2), laGP.nuggets=c('E',1e-6),laGP.nuggets.names=c('E',6),JMP.include=T,external.fits='JMP')
> #RGPP2_D4_B1.3(stepstorun=3, GPfit.powers=c(2), laGP.nuggets=c('E',1e-6),laGP.nuggets.names=c('E',6),JMP.include=T,external.fits='JMP')
> #RGPP2_D6_B1.3(stepstorun=3, GPfit.powers=c(2), laGP.nuggets=c('E',1e-6),laGP.nuggets.names=c('E',6),JMP.include=T,external.fits='JMP')
> 
> RGPP2_D2_B.7( stepstorun=1:3, GPfit.powers=c(2), laGP.nuggets=c('E',1e-6),laGP.nuggets.names=c('E',6),JMP.include=F, Python.include=T, GPy.include=T, GPfit.include=F, mlegp.include=F, Dice.include=T, laGP.include=F, DACE.include=F)
[1] "Starting DiceKriging"
/sscc/home/c/cbe117/.local/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.
  warnings.warn("Predicted variances smaller than 0. "
Starting Python
	1
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
	2
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
	3
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
	4
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
	5
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
/sscc/home/c/cbe117/.local/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.
  warnings.warn("Predicted variances smaller than 0. "
Starting Python
	1
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
	2
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
	3
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
	4
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
	5
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
Starting Python
	1
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
	2
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
	3
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
	4
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
	5
Shapes are:  (50, 2) (50, 1) (2000, 2) (2000, 1) 2 2 2 2
Starting GPy
	1
	2
	3
	4
	5
Starting GPy
	1
	2
	3
	4
	5
Starting GPy
	1
	2
	3
	4
	5
[1] "No color for sklearnRBF"
[1] "No color for sklearnMatern52"
[1] "No color for sklearnMatern32"
[1] "No color for GPyM32"
[1] "No color for GPyM52"
[1] "No color for Dice2"
[1] "No color for DiceM52"
[1] "No color for DiceM32"
               fit         rmse       prmse   poarmse      pwbrmse          xi
1      PredictMean 0.2163781251 0.214418680 0.9909443  142.9441659 1.283197480
2      PredictMean 0.2648303455 0.259188858 0.9786977  540.7159780 2.101051920
3      PredictMean 0.2512522460 0.242269149 0.9642467  160.1432681 2.053898301
4      PredictMean 0.2184905036 0.218911542 1.0019270  361.0884813 1.024363863
5      PredictMean 0.1981222843 0.193112691 0.9747146  145.2298557 1.044246401
6               LM 0.1686241818 0.167965956 0.9960965  111.1761601 1.000000000
7               LM 0.1260465498 0.134680688 1.0684996  256.8308384 1.000000000
8               LM 0.1223294483 0.104882421 0.8573767   77.4572771 1.000000000
9               LM 0.2132938417 0.216167821 1.0134743  352.4764301 1.000000000
10              LM 0.1897275242 0.189410615 0.9983297  139.0338613 1.000000000
11              QM 0.0865497632 0.082235407 0.9501517   56.5766772 0.513270174
12              QM 0.1189828795 0.126836804 1.0660089  242.3819539 0.943959828
13              QM 0.0831600839 0.074989058 0.9017434   52.3355936 0.679804292
14              QM 0.0982660586 0.099210374 1.0096098  161.8492192 0.460707434
15              QM 0.1260123975 0.122660476 0.9734001   92.0070777 0.664175628
16      sklearnRBF 0.3791913415 0.951028571 2.5080440  251.2546183 2.248736436
17      sklearnRBF 0.5189401418 1.000000000 1.9270045 1060.5028500 4.117051539
18      sklearnRBF 0.0015591855 0.002903142 1.8619609    0.0000000 0.012745790
19      sklearnRBF 0.6004064542 1.000000000 1.6655384  994.0101152 2.814926344
20      sklearnRBF 0.5038953053 1.000000000 1.9845392  370.9144368 2.655889321
21 sklearnMatern52 0.0047153834 0.007013752 1.4874193    2.1368787 0.027963862
22 sklearnMatern52 0.0038963069 0.004365342 1.1203793    6.9699767 0.030911650
23 sklearnMatern52 0.0068044755 0.007660129 1.1257486    3.3641219 0.055624182
24 sklearnMatern52 0.0033980565 0.004551078 1.3393178    4.6313528 0.015931339
25 sklearnMatern52 0.0037901566 0.009605070 2.5342145    1.7974342 0.019976841
26 sklearnMatern32 0.0079821109 0.013448295 1.6848043    4.3100483 0.047336691
27 sklearnMatern32 0.0059698454 0.009903489 1.6589188   11.2114430 0.047362228
28 sklearnMatern32 0.0097561192 0.012243692 1.2549756    5.2571895 0.079752826
29 sklearnMatern32 0.0056158909 0.010958171 1.9512791    8.3068091 0.026329362
30 sklearnMatern32 0.0074622348 0.018095570 2.4249531    4.5077172 0.039331324
31             GPy 0.0015032087 0.001960288 1.3040691    0.0000000 0.008914550
32             GPy 0.0006832486 0.001379264 2.0186855    0.3975992 0.005420605
33             GPy 0.0018931173 0.002708635 1.4307802    0.2141707 0.015475565
34             GPy 0.0007261602 0.001133566 1.5610412    0.2034126 0.003404506
35             GPy 0.0013548689 0.002171844 1.6029919    0.0000000 0.007141130
36          GPyM32 0.0080952231 0.013544513 1.6731489    4.3852954 0.048007486
37          GPyM32 0.0059169407 0.010055027 1.6993625   11.1032253 0.046942504
38          GPyM32 0.0098099462 0.012289034 1.2527117    5.2917121 0.080192843
39          GPyM32 0.0056706368 0.011114897 1.9600792    8.3975356 0.026586032
40          GPyM32 0.0074975799 0.018233885 2.4319694    4.5338047 0.039517618
41          GPyM52 0.0049068357 0.007130224 1.4531207    2.2642411 0.029099241
42          GPyM52 0.0039537713 0.004479945 1.1330814    7.0875213 0.031367548
43          GPyM52 0.0067687768 0.007637972 1.1284125    3.3412261 0.055332358
44          GPyM52 0.0034890821 0.004627257 1.3262103    4.7822031 0.016358101
45          GPyM52 0.0038065777 0.009736410 2.5577857    1.8095543 0.020063392
46           Dice2 0.0019214322 0.001899223 0.9884415    0.2782205 0.011394761
47           Dice2 0.0004888731 0.001201995 2.4587060    0.0000000 0.003878512
48           Dice2 0.0027946803 0.002495013 0.8927721    0.7923976 0.022845524
49           Dice2 0.0006034174 0.001003455 1.6629540    0.0000000 0.002829043
50           Dice2 0.0014911126 0.002000783 1.3418057    0.1005586 0.007859232
51         DiceM52 0.0054894172 0.007366801 1.3420006    2.6517997 0.032554151
52         DiceM52 0.0052374527 0.004197059 0.8013551    9.7133183 0.041551734
53         DiceM52 0.0086495490 0.008590064 0.9931228    4.5474791 0.070707005
54         DiceM52 0.0037795808 0.003840620 1.0161496    5.2636255 0.017720066
55         DiceM52 0.0059925772 0.009839133 1.6418867    3.4229941 0.031585176
56         DiceM32 0.0102169253 0.014318694 1.4014680    5.7967443 0.060589918
57         DiceM32 0.0086422148 0.009414420 1.0893527   16.6778300 0.068563676
58         DiceM32 0.0130870495 0.014375600 1.0984600    7.3935167 0.106982003
59         DiceM32 0.0067271744 0.009307962 1.3836362   10.1484587 0.031539468
60         DiceM32 0.0107279592 0.019391954 1.8076089    6.9180792 0.056544032
            pi rep elapsed        sigma2        delta      beta.1      beta.2
1  1.276560352   1   0.638  4.597537e-02 0.000000e+00  0.00000000  0.00000000
2  1.924469367   2   0.559  6.717886e-02 0.000000e+00  0.00000000  0.00000000
3  2.309911870   3   0.630  5.869434e-02 0.000000e+00  0.00000000  0.00000000
4  1.012692550   4   0.628  4.792226e-02 0.000000e+00  0.00000000  0.00000000
5  1.019545239   5   0.597  3.729251e-02 0.000000e+00  0.00000000  0.00000000
6  1.000000000   1   0.619  2.821256e-02 0.000000e+00  0.09661194  0.09661194
7  1.000000000   2   0.364  1.813889e-02 0.000000e+00  0.27042567  0.27042567
8  1.000000000   3   0.194  1.100032e-02 0.000000e+00  0.45638938  0.45638938
9  1.000000000   4   0.111  4.672853e-02 0.000000e+00 -0.15883453 -0.15883453
10 1.000000000   5   0.128  3.587638e-02 0.000000e+00 -0.12828001 -0.12828001
11 0.489595681   1   0.098  6.762662e-03 0.000000e+00  1.75343212  1.75343212
12 0.941759398   2   0.122  1.608757e-02 0.000000e+00  0.30288825  0.30288825
13 0.714982144   3   0.101  5.623359e-03 0.000000e+00  0.44458360  0.44458360
14 0.458950706   4   0.128  9.842698e-03 0.000000e+00 -1.86082832 -1.86082832
15 0.647590294   5   0.105  1.504559e-02 0.000000e+00  1.77346792  1.77346792
16 5.662031709   1   0.070 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
17 7.424969497   2   0.060 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
18 0.027679972   3   0.150 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
19 4.626035425   4   0.060 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
20 5.279535147   5   0.060 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
21 0.041756987   1   0.070 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
22 0.032412528   2   0.070 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
23 0.073035394   3   0.070 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
24 0.021053446   4   0.070 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
25 0.050710303   5   0.080 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
26 0.080065598   1   0.100 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
27 0.073533104   2   0.070 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
28 0.116737308   3   0.070 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
29 0.050692885   4   0.070 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
30 0.095536196   5   0.080 -1.234000e+03 1.000000e-10  1.00000000  1.00000000
31 0.011670746   1   0.670  1.412966e-01 1.445414e-17  0.33042367  0.33042367
32 0.010240993   2   0.690  9.458453e-02 1.362333e-14  0.31721093  0.31721093
33 0.025825440   3   0.660  1.511247e-01 2.481692e-16  0.31175251  0.31175251
34 0.005243916   4   0.900  1.115285e-01 2.251107e-15  0.32993776  0.32993776
35 0.011466326   5   0.620  2.067953e-01 6.896217e-15  0.33280902  0.33280902
36 0.080638445   1   0.470  6.532291e-01 1.783978e-12  1.77892597  1.77892597
37 0.074658272   2   0.460  3.520101e-01 1.247804e-12  1.67623226  1.67623226
38 0.117169625   3   0.600  5.850251e-01 2.021630e-12  1.65959922  1.65959922
39 0.051417909   4   0.490  4.100709e-01 1.449215e-12  1.58254876  1.58254876
40 0.096266434   5   0.550  5.448906e-01 3.287472e-12  1.21887113  1.21887113
41 0.042450413   1   0.500  4.712338e-01 5.255689e-13  0.90414827  0.90414827
42 0.033263453   2   0.490  3.159521e-01 2.649923e-13  0.95351163  0.95351163
43 0.072824142   3   0.460  3.775204e-01 4.585124e-13  0.84111834  0.84111834
44 0.021405854   4   0.440  5.509506e-01 3.555492e-13  1.04187697  1.04187697
45 0.051403719   5   0.570  4.992610e-01 1.045937e-12  0.74053057  0.74053057
46 0.011307193   1   0.843  6.765703e-02 5.472311e-09  0.31209647  0.31209647
47 0.008924777   2   0.256  4.968587e-02 4.968587e-10  0.30458145  0.30458145
48 0.023788663   3   0.350  6.627885e-02 6.627885e-10  0.29318152  0.29318152
49 0.004642020   4   0.347  5.984307e-02 1.863626e-09  0.31529155  0.31529155
50 0.010563206   5   0.238  8.640260e-02 8.640260e-10  0.30911981  0.30911981
51 0.043858893   1   0.686  7.843104e-02 7.843104e-10  0.48460795  0.48460795
52 0.031163038   2   0.768  6.769353e-02 6.769353e-10  0.59435427  0.59435427
53 0.081901847   3   0.711  5.049575e-02 5.049575e-10  0.41435284  0.41435284
54 0.017766843   4   0.698  1.034061e-01 1.034061e-09  0.60497642  0.60497642
55 0.051946048   5   1.670  7.972608e-02 7.972608e-10  0.42214658  0.42214658
56 0.085247597   1   0.707  5.530881e-02 5.530882e-10  0.58911889  0.58911889
57 0.069901783   2   0.680  5.402284e-02 5.402284e-10  0.71589546  0.71589546
58 0.137063960   3   0.686  4.061656e-02 4.061657e-10  0.47696159  0.47696159
59 0.043058962   4   0.677  8.955414e-02 8.955414e-10  0.74852744  0.74852744
60 0.102380503   5   0.670  4.629923e-02 4.629923e-10  0.43483017  0.43483017
   input.dim input.ss pred.ss seed.start seed.preds seed.fit func.string
1          2       50    2000       1028       1128     1328            
2          2       50    2000       1029       1129     1329            
3          2       50    2000       1030       1130     1330            
4          2       50    2000       1031       1131     1331            
5          2       50    2000       1032       1132     1332            
6          2       50    2000       1028       1128     1328            
7          2       50    2000       1029       1129     1329            
8          2       50    2000       1030       1130     1330            
9          2       50    2000       1031       1131     1331            
10         2       50    2000       1032       1132     1332            
11         2       50    2000       1028       1128     1328            
12         2       50    2000       1029       1129     1329            
13         2       50    2000       1030       1130     1330            
14         2       50    2000       1031       1131     1331            
15         2       50    2000       1032       1132     1332            
16         2       50    2000       1028       1128     1328            
17         2       50    2000       1029       1129     1329            
18         2       50    2000       1030       1130     1330            
19         2       50    2000       1031       1131     1331            
20         2       50    2000       1032       1132     1332            
21         2       50    2000       1028       1128     1328            
22         2       50    2000       1029       1129     1329            
23         2       50    2000       1030       1130     1330            
24         2       50    2000       1031       1131     1331            
25         2       50    2000       1032       1132     1332            
26         2       50    2000       1028       1128     1328            
27         2       50    2000       1029       1129     1329            
28         2       50    2000       1030       1130     1330            
29         2       50    2000       1031       1131     1331            
30         2       50    2000       1032       1132     1332            
31         2       50    2000       1028       1128     1328            
32         2       50    2000       1029       1129     1329            
33         2       50    2000       1030       1130     1330            
34         2       50    2000       1031       1131     1331            
35         2       50    2000       1032       1132     1332            
36         2       50    2000       1028       1128     1328            
37         2       50    2000       1029       1129     1329            
38         2       50    2000       1030       1130     1330            
39         2       50    2000       1031       1131     1331            
40         2       50    2000       1032       1132     1332            
41         2       50    2000       1028       1128     1328            
42         2       50    2000       1029       1129     1329            
43         2       50    2000       1030       1130     1330            
44         2       50    2000       1031       1131     1331            
45         2       50    2000       1032       1132     1332            
46         2       50    2000       1028       1128     1328            
47         2       50    2000       1029       1129     1329            
48         2       50    2000       1030       1130     1330            
49         2       50    2000       1031       1131     1331            
50         2       50    2000       1032       1132     1332            
51         2       50    2000       1028       1128     1328            
52         2       50    2000       1029       1129     1329            
53         2       50    2000       1030       1130     1330            
54         2       50    2000       1031       1131     1331            
55         2       50    2000       1032       1132     1332            
56         2       50    2000       1028       1128     1328            
57         2       50    2000       1029       1129     1329            
58         2       50    2000       1030       1130     1330            
59         2       50    2000       1031       1131     1331            
60         2       50    2000       1032       1132     1332            
     batch.name
1  RGPP2_D2_B.7
2  RGPP2_D2_B.7
3  RGPP2_D2_B.7
4  RGPP2_D2_B.7
5  RGPP2_D2_B.7
6  RGPP2_D2_B.7
7  RGPP2_D2_B.7
8  RGPP2_D2_B.7
9  RGPP2_D2_B.7
10 RGPP2_D2_B.7
11 RGPP2_D2_B.7
12 RGPP2_D2_B.7
13 RGPP2_D2_B.7
14 RGPP2_D2_B.7
15 RGPP2_D2_B.7
16 RGPP2_D2_B.7
17 RGPP2_D2_B.7
18 RGPP2_D2_B.7
19 RGPP2_D2_B.7
20 RGPP2_D2_B.7
21 RGPP2_D2_B.7
22 RGPP2_D2_B.7
23 RGPP2_D2_B.7
24 RGPP2_D2_B.7
25 RGPP2_D2_B.7
26 RGPP2_D2_B.7
27 RGPP2_D2_B.7
28 RGPP2_D2_B.7
29 RGPP2_D2_B.7
30 RGPP2_D2_B.7
31 RGPP2_D2_B.7
32 RGPP2_D2_B.7
33 RGPP2_D2_B.7
34 RGPP2_D2_B.7
35 RGPP2_D2_B.7
36 RGPP2_D2_B.7
37 RGPP2_D2_B.7
38 RGPP2_D2_B.7
39 RGPP2_D2_B.7
40 RGPP2_D2_B.7
41 RGPP2_D2_B.7
42 RGPP2_D2_B.7
43 RGPP2_D2_B.7
44 RGPP2_D2_B.7
45 RGPP2_D2_B.7
46 RGPP2_D2_B.7
47 RGPP2_D2_B.7
48 RGPP2_D2_B.7
49 RGPP2_D2_B.7
50 RGPP2_D2_B.7
51 RGPP2_D2_B.7
52 RGPP2_D2_B.7
53 RGPP2_D2_B.7
54 RGPP2_D2_B.7
55 RGPP2_D2_B.7
56 RGPP2_D2_B.7
57 RGPP2_D2_B.7
58 RGPP2_D2_B.7
59 RGPP2_D2_B.7
60 RGPP2_D2_B.7
Warning message:
In comparison.compare(path.base = path.base, batch.name = batch.name,  :
  Setting RMSE/LM plot limits!!! in version 2 #42498
> 
> 
> timestamp()
##------ Wed Jan 11 10:00:24 2017 ------##
> print(getwd())
[1] "/sscc/home/c/cbe117/Research/GPC"
> timestamp()
##------ Wed Jan 11 10:00:24 2017 ------##
> 
> proc.time()
   user  system elapsed 
 74.180  15.263 263.047 
